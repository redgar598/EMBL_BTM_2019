{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BTM Data science notebook\n",
    "\n",
    "In this session we will use examples from https://github.com/pycam/python-data-science condensed down to a 1 and a half hour session, to get familiar with pandas and classes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas \n",
    "Pandas is a data analysis module that allows you to use python with tables and data objects, much like data.frames in R.\n",
    "\n",
    "Lets get started by opening a table and look at some data using pandas. We will also look at how to do the same tasks in python and see how much simpler pandas can be sometimes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading a table without pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "data = []\n",
    "with open(\"data/genes.txt\") as f:\n",
    "    reader = csv.DictReader(f, delimiter = \"\\t\")\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "# look at the data\n",
    "for d in data:\n",
    "    print(d['gene'], d['chrom'], d['start'], d['end'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the same data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/genes.txt\", sep = \"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, using pandas you can be quicker in writing code that handles data tables, but you also do not have total control over what happens, so sometimes using pandas might not what you need. This you will have to decide every times new."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data\n",
    "When you firts open a data file in jupyter lab, you might want to check that the data was correctly loaded. A good way to do this is to actually lookt at the data. Pandas allows you to do this. Lets check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pandas, although it should already be loaded into this kernel\n",
    "import pandas as pd\n",
    "# open a dataset\n",
    "df = pd.read_csv('data/GRCm38.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check out the column types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how large is the table (rows, columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the column names\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for numeric data pandas can give you some stats, so you can check for basic errors\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting the table based on column\n",
    "df = df.sort_values(['start', 'end', 'strand'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first two rows\n",
    "df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only the first two seqids\n",
    "df[:2]['seqid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by value and show top hits\n",
    "df[df.type == \"CDS\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### selecting using iloc and loc\n",
    "We see that `.iloc[0]` will return the first row in the DataFrame, while `.loc[0]` will return the row with index 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To summarise..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a column by name\n",
    "df['seqid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting columns by name\n",
    "df[['seqid', 'source']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting rows\n",
    "df[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting by position - on both axes\n",
    "df.iloc[1:3, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting by label - on both axes\n",
    "df.loc[[1, 2, 3], ['seqid', 'source']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some quick exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many rows have a source of 'Gnomon'?\n",
    "- Which seqid has the largest value in the 'end' column?\n",
    "- What are all the unique values in the 'type' column?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and Classes\n",
    "When we write code it is good practice to use functions and classes. They provide structure for your code and make it not only understandable but also reusable. \n",
    "\n",
    "## Functions\n",
    "Functions are short generalized code structures that can be called with an input then do some computation and return an output. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def this_is_the_function_name(input_argument1, input_argument2):\n",
    "\n",
    "    # The body of the function is indented\n",
    "    # This function prints the two arguments to screen\n",
    "    print('The function arguments are:', input_argument1, \"and\", input_argument2, '\\n(this is done inside the function!)')\n",
    "\n",
    "    # And returns their product\n",
    "    return input_argument1 * input_argument2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function\n",
    "r = this_is_the_function_name(100, 2)\n",
    "print(f\"The result of the computation is: {r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square (x):\n",
    "    result = x*x\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(square(2))\n",
    "print(square(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes\n",
    "Classes are larger structures that are defined to group functions around a root case together. Commonly they provide functions for a certain data object. So you could for example imagine a tsv class, which provides functionality like loading, sorting and filtering of a tsv file. Here is an example how this could look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tsvClass():\n",
    "    def __init__(self, path, autoload = False):\n",
    "        '''\n",
    "        When initialized the class will always execute this __init__ function.\n",
    "        So whatever we do here, will always be done.\n",
    "        '''\n",
    "        self.path = path\n",
    "        if autoload:\n",
    "            self.load()\n",
    "    \n",
    "    def load(self):\n",
    "        '''\n",
    "        In this function we load the tsv file by using pandas\n",
    "        '''\n",
    "        self.df = pd.read_csv(self.path, sep = '\\t')\n",
    "    \n",
    "    def filter(self, column = \"type\", match = \"CDS\"):\n",
    "        '''\n",
    "        This filter function takes two arguments and returns a subset\n",
    "        based on these\n",
    "        '''\n",
    "        return self.df[self.df[column] == match]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRCm38 = tsvClass('data/GRCm38.tsv')\n",
    "GRCm38.load()\n",
    "GRCm38.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can use our filter function to reduce to exons\n",
    "GRCm38.filter(match = \"exon\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or we filter on the strand\n",
    "GRCm38.filter(column = \"strand\", match = \"+\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And because this is a class we now can go back to the tsv object and just ask it what file it was from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRCm38.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope you now got a glimpse in how to write functions, you will need time and practize to write classes that are not just spagetti code in disguise but it is worth it.\n",
    "\n",
    "Often a script can be split into functions and then put into a class which makes it more understandable and you will find bugs much quicker.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project \n",
    "We want to query ensembl with coding regions from different species. For this in the data folder you find the gff files of mouse, human and zebra fish. We will load the gff3 files and sample 100 coding sequences (CDS) for each and compare GC content between species by plotting the result. \n",
    "\n",
    "You find all needed code here you just need to make it work. If you have the time, make it nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, sys\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genomic_content(chrom, start, end, species = 'human'):\n",
    "    server = \"https://rest.ensembl.org\"\n",
    "    ext = f\"/sequence/region/{species}/{chrom}:{start}..{end}:1?\"\n",
    "\n",
    "    r = requests.get(server+ext, headers={ \"Content-Type\" : \"text/plain\"})\n",
    "\n",
    "    if not r.ok:\n",
    "      r.raise_for_status()\n",
    "\n",
    "    return r.text\n",
    "\n",
    "def calculateGC(seq):\n",
    "    '''\n",
    "    takes a genomic sequence and only counts AGCT items and returns simple GC content\n",
    "    Ambigious bases are ignored\n",
    "    '''\n",
    "    seq = seq.lower()\n",
    "    d = {}\n",
    "    for c in \"agct\":\n",
    "        d[c] = seq.count(c)\n",
    "    gc = (d['g'] + d['c'])/(d['a'] + d['g'] + d['c'] + d['t'])\n",
    "    return gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gff3():\n",
    "    '''\n",
    "    This is a custom class for parsing esembles gff3 format\n",
    "    Usually you might want to resort to known established parsers such as \n",
    "    provided by biopython: https://biopython.org/wiki/GFF_Parsing\n",
    "    But their gff parser is not yet done. \n",
    "    For fasta and other file formats you can always rely on them though.\n",
    "    '''\n",
    "    def __init__(self, path, autoload = True):\n",
    "        '''\n",
    "        When initialized the class will always execute this __init__ function.\n",
    "        So whatever we do here, will always be done.\n",
    "        '''\n",
    "        self.path = path\n",
    "        if autoload:\n",
    "            self.load()\n",
    "    \n",
    "    def load(self):\n",
    "        '''\n",
    "        In this function we load the gff3 file by using pandas\n",
    "        '''\n",
    "        knownnames = ['seqid', 'source', 'type',\n",
    "                      'start', 'end', 'score', \n",
    "                      'strand', 'phase', 'attributes']\n",
    "        self.df = pd.read_csv(self.path, sep = '\\t', comment=\"#\", names = knownnames)\n",
    "    \n",
    "    def filter(self, column = \"type\", match = \"CDS\"):\n",
    "        '''\n",
    "        This filter function takes two arguments and returns a subset\n",
    "        based on these\n",
    "        '''\n",
    "        return self.df[self.df[column] == match]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mouse gff3 file\n",
    "c = gff3('data/Mus_musculus.GRCm38.98.gff3.gz')\n",
    "# then filter for CDS regions\n",
    "df = c.filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize an empty list to store the results\n",
    "res = []\n",
    "# iterate the dataframe after sampleing\n",
    "for index, row in df.sample(100).iterrows():\n",
    "    # fetch the sequence using the esemble API\n",
    "    seq = get_genomic_content(row.seqid, row.start, row.end, species = 'mouse')\n",
    "    # calculate the GC content\n",
    "    gc = calculateGC(seq)\n",
    "    # create a dictionary for each result\n",
    "    result = {'species': 'mouse',\n",
    "              'gc': gc}\n",
    "    # and save this in out result list\n",
    "    res.append(result)\n",
    "\n",
    "# transform the dictionary into a data frame\n",
    "result_df = pd.DataFrame(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot simple historgram\n",
    "result_df.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you saw how to do it for one species, you can do the same for human and zebrafish and plot them together. You can merge pandas dataframes using `pd.concat`. Check the documentation for help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['Danio_rerio.GRCz11.98.gff3.gz', 'Homo_sapiens.GRCh38.98.gff3.gz',  'Mus_musculus.GRCm38.98.gff3.gz']\n",
    "species =  ['Zebrafish', 'Human', 'Mouse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"only scroll down If you want to see my solution. Else work in here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution\n",
    "class gffsample(gff3):\n",
    "    '''\n",
    "    this class inherits the functionality of the gff class and \n",
    "    expands it with new functionality for sampeling. But relies on outside functions\n",
    "    for computing gc and fetching the data.\n",
    "    Would be nice to include these into this class.\n",
    "    '''\n",
    "    def __init__(self, path, species = \"human\"):\n",
    "        '''\n",
    "        When initialized the class will always execute this __init__ function.\n",
    "        So whatever we do here, will always be done.\n",
    "        '''\n",
    "        self.path = path\n",
    "        # filter\n",
    "        self.load()\n",
    "        # also filter this time\n",
    "        self.df = self.filter()\n",
    "        # set the species\n",
    "        self.species = species\n",
    "        self.df_gc_created = False\n",
    "    \n",
    "    def sample(self, n = 100):\n",
    "        self.sampled = self.df.sample(n)\n",
    "    \n",
    "    def make_GC(self):\n",
    "        res = []\n",
    "        for index, row in self.sampled.iterrows():\n",
    "            # fetch the sequence using the esemble API\n",
    "            seq = get_genomic_content(row.seqid, row.start, row.end, species = self.species)\n",
    "            # calculate the GC content\n",
    "            gc = calculateGC(seq)\n",
    "            # create a dictionary for each result\n",
    "            result = {'species': self.species,\n",
    "                      'gc': gc}\n",
    "            # and save this in out result list\n",
    "            res.append(result)\n",
    "        # transform the dictionary into a data frame\n",
    "        self.df_gc = pd.DataFrame(res)\n",
    "    \n",
    "    def get_GC(self):\n",
    "        # if not done already compute the GC content by querying the esemble api\n",
    "        if self.df_gc_created == False:\n",
    "            self.make_GC()\n",
    "            self.df_gc_created = True\n",
    "        \n",
    "        return self.df_gc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "for file, specie in zip(files, species):\n",
    "    print(f'Sampling file: {file} ({specie})')\n",
    "    g = gffsample(f'data/{file}', species = specie)\n",
    "    g.sample(100)\n",
    "    dataframes.append(g.get_GC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(dataframes).hist(by = \"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modules are a great way to structure / share your code to make it easily re-usable. Modules are simply python scripts (.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import example_module as exp\n",
    "\n",
    "res = []\n",
    "# iterate the dataframe after sampling\n",
    "for index, row in df.sample(3).iterrows():\n",
    "    # fetch the sequence using the ensembl API\n",
    "    seq = exp.get_genomic_content(row.seqid, row.start, row.end, species = 'mouse')\n",
    "    # calculate the GC content\n",
    "    gc = exp.calculateGC(seq)\n",
    "    # create a dictionary for each result\n",
    "    result = {'species': 'mouse',\n",
    "              'gc': gc}\n",
    "    # and save this in out result list\n",
    "    res.append(result)\n",
    "    \n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages like Pandas etc... are simply collections of modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing python environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments are a way to manage which version of Python / packages you use. Setting up multiple environments, can allow you to quickly switch between different package versions...\n",
    "\n",
    "The most popular ways to do this are with 'virtualenv' and 'conda'. Here we cover using conda:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default you will have a base environment with all your current packages. You can list available functions by typing the following command in the terminal:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda env list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make a new environment like so:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda create --name mynewenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use a new environment we must 'activate' it:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda activate mynewenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also list the packages in our current environment:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save our environments as .yml files, that others can then use to create the exact same environment"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda env export > environment.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create an environment from a .yml file:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda env create --name mynewenv2 -f environment.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#id3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More info?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The full Cambridge course: http://pycam.github.io/ \n",
    "- Bio-IT courses: https://bio-it.embl.de/\n",
    "- EMBL chat - python & R channels\n",
    "- EPUG & emblr\n",
    "- Useful packages: https://www.scipy.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
